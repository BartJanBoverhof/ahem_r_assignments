times_start <- c(times_start, rep(data_times$n_last_time_point, data_times$n_patients_at_risk))
times_end   <- c(times_end, rep(10000, data_times$n_patients_at_risk))
for (d in distributions) {
model <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = d)
n_AIC <- -2 * summary(model)$loglik[1] + 2 * ifelse(d == "exponential", 1 , 2)
n_intercept <- summary(model)$table[1]
n_log_scale <- ifelse(d != "exponential", summary(model)$table[2], NA)
m_cholesky  <- t(chol(summary(model)$var))
l_results[[d]] <- list(model     = model,
AIC       = n_AIC,
intercept = n_intercept,
log_scale = n_log_scale,
cholesky  = m_cholesky)
m_model_parameters["AIC",        which(d == distributions)] <- n_AIC
m_model_parameters["intercept",  which(d == distributions)] <- n_intercept
m_model_parameters["log(scale)", which(d == distributions)] <- n_log_scale
m_model_parameters <- round(m_model_parameters, 4)
}
l_results$summary <- m_model_parameters
return(l_results)
}
l_results_all <- list()
for (df in names(l_data_survival)) {
l_results_all[[df]] <- get_survival_parameters(data_survival = l_data_survival[[df]], data_times = l_times[[df]])
}
saveRDS(l_results_all, file = "output/l_results_all.rds")
library(openxlsx)
wb <- createWorkbook("AHEM student")
addWorksheet(wb, "PFS caba", gridLines = FALSE, tabColour = "coral")
addWorksheet(wb, "PFS mito", gridLines = FALSE, tabColour = "coral3")
addWorksheet(wb, "OS caba",  gridLines = FALSE, tabColour = "skyblue")
addWorksheet(wb, "OS mito",  gridLines = FALSE, tabColour = "skyblue4")
for (i in v_names_data) {
print(i)
print(l_results_all[[i]]$summary)
writeData(wb, sheet = i, x = l_results_all[[i]]$summary, rowNames = TRUE)
}
saveWorkbook(wb, "output/output_parametric_survival_model_parameters.xlsx", overwrite = TRUE)
rm(list = ls(all = TRUE)) # Clear all information in the environment
# Uncomment the following line if you need to install the packages
# install.packages(c("survival", "readxl", "openxlsx"))
library(survival)         # Load the survival package
library(readxl)           # Load the readxl package
library(openxlsx)         # Load the openxlsx package
# Load the data from Excel
# Ensure the Excel file is populated with the necessary information.
df_OS_mito       <- na.omit(read_excel("data/Hoyle_and_Henley_Bahl_OS_Mito.xlsm", sheet = "R data", range = cell_cols("A:F")))
df_times_OS_mito <- na.omit(read_excel("data/Hoyle_and_Henley_Bahl_OS_Mito.xlsm", sheet = "R data", range = cell_cols("G:H")))
data <- df_OS_mito
attach(data) # You can ignore the warning about "masked objects"
v_names_trt  <- c("Cabazitaxel", "Mitoxantrone") # vector with the treatment names
v_names_data <- c("PFS caba","PFS mito", "OS caba", "OS mito") # vector for the different data sets
v_names_dist <- c("exponential", "weibull", "lognormal", "loglogistic") # define the distribution we are evaluating
times_start <- c(rep(start_time_censor, n_censors), rep(start_time_event, n_events))
times_end   <- c(rep(end_time_censor, n_censors),   rep(end_time_event,   n_events))
# Adding times for patients at risk at the last time point
times_start <- c(times_start, rep(df_times_OS_mito$n_last_time_point, df_times_OS_mito$n_patients_at_risk))
times_end   <- c(times_end,   rep(10000, df_times_OS_mito$n_patients_at_risk))
df_times    <- cbind(times_start, times_end)
head(df_times)
model_exp  <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = "exponential")   # Exponential function
model_wei  <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = "weibull")       # Weibull function
model_logn <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = "lognormal")     # Lognormal function
model_logl <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = "loglogistic")   # Log-logistic function
AIC_exp  <- -2 * summary(model_exp)$loglik[1]  + 2 * 1
AIC_wei  <- -2 * summary(model_wei)$loglik[1]  + 2 * 2
AIC_logn <- -2 * summary(model_logn)$loglik[1] + 2 * 2
AIC_logl <- -2 * summary(model_logl)$loglik[1] + 2 * 2
v_AIC <- c(exponential = AIC_exp,
weibull     = AIC_wei,
lognormal   = AIC_logn,
loglogistic = AIC_logl)
v_AIC # print the AIC values
v_AIC[order(-v_AIC)] # print the values in order
intercept_exp  <- summary(model_exp)$table ["(Intercept)", "Value"]
intercept_wei  <- summary(model_wei)$table ["(Intercept)", "Value"]
intercept_logn <- summary(model_logn)$table["(Intercept)", "Value"]
intercept_logl <- summary(model_logl)$table["(Intercept)", "Value"]
log_scale_wei  <- summary(model_wei)$table ["Log(scale)", "Value"]
log_scale_logn <- summary(model_logn)$table["Log(scale)", "Value"]
log_scale_logl <- summary(model_logl)$table["Log(scale)", "Value"]
v_intercept        <- c(intercept_exp, intercept_wei, intercept_logn, intercept_logl)
v_log_scale        <- c(NA,            log_scale_wei, log_scale_logn, log_scale_logl)
names(v_intercept) <- names(v_intercept) <- v_names_dist
m_model_parameters_OS_mito <- matrix(NA, nrow = 3, ncol = length(v_names_dist),
dimnames = list(c("AIC", "intercept", "log(scale)"),
v_names_dist))
m_model_parameters_OS_mito["AIC",  ]       <- v_AIC
m_model_parameters_OS_mito["intercept",  ] <- v_intercept
m_model_parameters_OS_mito["log(scale)", ] <- v_log_scale
m_model_parameters_OS_mito <- round(m_model_parameters_OS_mito, 4)
m_model_parameters_OS_mito
rm(list = ls(all = TRUE)) # Clear all information in the environment
# Uncomment the following line if you need to install the packages
# install.packages(c("survival", "readxl", "openxlsx"))
library(survival)         # Load the survival package
library(readxl)           # Load the readxl package
library(openxlsx)         # Load the openxlsx package
# Load the data from Excel
# Ensure the Excel file is populated with the necessary information.
df_OS_mito       <- na.omit(read_excel("data/Hoyle_and_Henley_Bahl_OS_Mito.xlsm", sheet = "R data", range = cell_cols("A:F")))
df_times_OS_mito <- na.omit(read_excel("data/Hoyle_and_Henley_Bahl_OS_Mito.xlsm", sheet = "R data", range = cell_cols("G:H")))
data <- df_OS_mito
attach(data) # You can ignore the warning about "masked objects"
v_names_trt  <- c("Cabazitaxel", "Mitoxantrone") # vector with the treatment names
v_names_data <- c("PFS caba","PFS mito", "OS caba", "OS mito") # vector for the different data sets
v_names_dist <- c("exponential", "weibull", "lognormal", "loglogistic") # define the distribution we are evaluating
times_start <- c(rep(start_time_censor, n_censors), rep(start_time_event, n_events))
times_end   <- c(rep(end_time_censor, n_censors),   rep(end_time_event,   n_events))
# Adding times for patients at risk at the last time point
times_start <- c(times_start, rep(df_times_OS_mito$n_last_time_point, df_times_OS_mito$n_patients_at_risk))
times_end   <- c(times_end,   rep(10000, df_times_OS_mito$n_patients_at_risk))
df_times    <- cbind(times_start, times_end)
head(df_times)
model_exp  <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = "exponential")   # Exponential function
model_wei  <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = "weibull")       # Weibull function
model_logn <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = "lognormal")     # Lognormal function
model_logl <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = "loglogistic")   # Log-logistic function
AIC_exp  <- -2 * summary(model_exp)$loglik[1]  + 2 * 1
AIC_wei  <- -2 * summary(model_wei)$loglik[1]  + 2 * 2
AIC_logn <- -2 * summary(model_logn)$loglik[1] + 2 * 2
AIC_logl <- -2 * summary(model_logl)$loglik[1] + 2 * 2
v_AIC <- c(exponential = AIC_exp,
weibull     = AIC_wei,
lognormal   = AIC_logn,
loglogistic = AIC_logl)
v_AIC # print the AIC values
v_AIC[order(-v_AIC)] # print the values in order
intercept_exp  <- summary(model_exp)$table ["(Intercept)", "Value"]
intercept_wei  <- summary(model_wei)$table ["(Intercept)", "Value"]
intercept_logn <- summary(model_logn)$table["(Intercept)", "Value"]
intercept_logl <- summary(model_logl)$table["(Intercept)", "Value"]
log_scale_wei  <- summary(model_wei)$table ["Log(scale)", "Value"]
log_scale_logn <- summary(model_logn)$table["Log(scale)", "Value"]
log_scale_logl <- summary(model_logl)$table["Log(scale)", "Value"]
v_intercept        <- c(intercept_exp, intercept_wei, intercept_logn, intercept_logl)
v_log_scale        <- c(NA,            log_scale_wei, log_scale_logn, log_scale_logl)
names(v_intercept) <- names(v_intercept) <- v_names_dist
m_model_parameters_OS_mito <- matrix(NA, nrow = 3, ncol = length(v_names_dist),
dimnames = list(c("AIC", "intercept", "log(scale)"),
v_names_dist))
m_model_parameters_OS_mito["AIC",  ]       <- v_AIC
m_model_parameters_OS_mito["intercept",  ] <- v_intercept
m_model_parameters_OS_mito["log(scale)", ] <- v_log_scale
m_model_parameters_OS_mito <- round(m_model_parameters_OS_mito, 4)
m_model_parameters_OS_mito
cholesky_exp  <- t(chol(summary(model_exp)$var))
cholesky_wei  <- t(chol(summary(model_wei)$var))
cholesky_logn <- t(chol(summary(model_logn)$var))
cholesky_logl <- t(chol(summary(model_logl)$var))
l_cholesky <- list("exponential"  = cholesky_exp,
"weibull"      = cholesky_wei,
"lognormal"    = cholesky_logn,
"loglogistic"  = cholesky_logl)
l_cholesky
library(readxl)           # Load the readxl package
# Load the data from the Excel files
df_PFS_caba <- na.omit(read_excel("data/Hoyle_and_Henley_PFS_Caba.xlsm",     sheet = "R data", range = cell_cols("A:F")))
df_PFS_mito <- na.omit(read_excel("data/Hoyle_and_Henley_PFS_Mito.xlsm",     sheet = "R data", range = cell_cols("A:F")))
df_OS_caba  <- na.omit(read_excel("data/Hoyle_and_Henley_Bahl_OS_Caba.xlsm", sheet = "R data", range = cell_cols("A:F")))
# Create a list with the dataframes
l_data_survival <- list("PFS caba" = df_PFS_caba,
"PFS mito" = df_PFS_mito,
"OS caba"  = df_OS_caba,
"OS mito"  = df_OS_mito)
# Add the time of the last time point and the number of patients at risk
df_times_PFS_caba <- na.omit(read_excel("data/Hoyle_and_Henley_PFS_Caba.xlsm",     sheet = "R data", range = cell_cols("G:H")))
df_times_PFS_mito <- na.omit(read_excel("data/Hoyle_and_Henley_PFS_Mito.xlsm",     sheet = "R data", range = cell_cols("G:H")))
df_times_OS_caba  <- na.omit(read_excel("data/Hoyle_and_Henley_Bahl_OS_Caba.xlsm", sheet = "R data", range = cell_cols("G:H")))
# Create a list with the data for time points
l_times <- list("PFS caba" = df_times_PFS_caba,
"PFS mito" = df_times_PFS_mito,
"OS caba"  = df_times_OS_caba,
"OS mito"  = df_times_OS_mito)
get_survival_parameters <- function(data_survival, data_times, distributions = c("exponential", "weibull", "lognormal", "loglogistic")) {
l_results <- l_model <- l_cholesky <- list()
v_AIC <- v_intercept <- v_log_scale <- vector()
m_model_parameters <- matrix(NA, nrow = 3, ncol = length(distributions),
dimnames = list(c("AIC", "intercept", "log(scale)"),
distributions))
times_start <- c(rep(data_survival$start_time_censor, data_survival$n_censors), rep(data_survival$start_time_event, data_survival$n_events))
times_end   <- c(rep(data_survival$end_time_censor, data_survival$n_censors),   rep(data_survival$end_time_event,   data_survival$n_events))
times_start <- c(times_start, rep(data_times$n_last_time_point, data_times$n_patients_at_risk))
times_end   <- c(times_end, rep(10000, data_times$n_patients_at_risk))
for (d in distributions) {
model <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = d)
n_AIC <- -2 * summary(model)$loglik[1] + 2 * ifelse(d == "exponential", 1 , 2)
n_intercept <- summary(model)$table[1]
n_log_scale <- ifelse(d != "exponential", summary(model)$table[2], NA)
m_cholesky  <- t(chol(summary(model)$var))
l_results[[d]] <- list(model     = model,
AIC       = n_AIC,
intercept = n_intercept,
log_scale = n_log_scale,
cholesky  = m_cholesky)
m_model_parameters["AIC",        which(d == distributions)] <- n_AIC
m_model_parameters["intercept",  which(d == distributions)] <- n_intercept
m_model_parameters["log(scale)", which(d == distributions)] <- n_log_scale
m_model_parameters <- round(m_model_parameters, 4)
}
l_results$summary <- m_model_parameters
return(l_results)
}
l_results_all <- list()
for (df in names(l_data_survival)) {
l_results_all[[df]] <- get_survival_parameters(data_survival = l_data_survival[[df]], data_times = l_times[[df]])
}
saveRDS(l_results_all, file = "output/l_results_all.rds")
library(openxlsx)
wb <- createWorkbook("AHEM student")
addWorksheet(wb, "PFS caba", gridLines = FALSE, tabColour = "coral")
addWorksheet(wb, "PFS mito", gridLines = FALSE, tabColour = "coral3")
addWorksheet(wb, "OS caba",  gridLines = FALSE, tabColour = "skyblue")
addWorksheet(wb, "OS mito",  gridLines = FALSE, tabColour = "skyblue4")
for (i in v_names_data) {
print(i)
print(l_results_all[[i]]$summary)
writeData(wb, sheet = i, x = l_results_all[[i]]$summary, rowNames = TRUE)
}
saveWorkbook(wb, "output/output_parametric_survival_model_parameters.xlsx", overwrite = TRUE)
# Ignore this code for now, used for the solutions
# source("solution_estimate survival prob.R")
# Extract the results for OS Mito
l_OS_mito <- l_results_all$`OS mito`
t_weeks <- 15           # number of weeks
t <- (t_weeks/ 52) * 12 # time in months
cat(t_weeks, "weeks is the same as", round(t, 3), "months", "\n")
t_weeks <- 15           # number of weeks
t <- (t_weeks/ 52) * 12 # time in months
cat(t_weeks, "weeks is the same as", round(t, 3), "months", "\n")
### Exponential ###
# Function to calculate survival probability using the Exponential distribution
exponential_survival <- function(t, intercept) {
# t: time point in months at which the survival probability is estimated
# intercept: estimate of the intercept for the survival curve (from model fit)
# Calculate lambda (scale parameter) based on the intercept value.
# Here, lambda is the exponential of the negative of the intercept.
lambda <- exp(-intercept)  # Scale parameter for the Exponential distribution
# Calculate the survival probability at time t using the Exponential survival function.
S_t <- exp(-t * lambda)
return(S_t)   # Return the calculated survival probability at time t
}
# Calculation for exponential distribution
intercept_exp   <- l_OS_mito$exponential$intercept
p_survival_exp  <- exponential_survival(t, intercept_exp)
cat("Survival probability (Exponential) at: ", round(52/t), "weeks :", p_survival_exp, "\n")
# YOUR TURN ##
### weibull ###
#p_survival_weibull
### lognormal ###
#p_survival_lognormal
### Exponential ###
#p_survival_loglogistic
## Summary ##
# Combine and display results
#v_survival_props <- round(c(p_survival_exp, p_survival_weibull, p_survival_lognormal, p_survival_loglogistic), 4)
#names(v_survival_props) <- c("exponential", "weibull", "lognormal", "loglogistic")
#round(v_survival_props, 3) * 100
m_cholesky_exponential <- matrix(NA, nrow = 1, ncol = 4,
dimnames = list("exponential",
rev(v_names_data)))
# Create a list for the cholesky matrix
l_cholesky_weibull <- l_cholesky_lognormal <- l_cholesky_loglogistic <- list()
# Create table for the Cholesky matrices
for (i in v_names_data){
m_cholesky_exponential[, i] <- (l_results_all[[i]]$exponential$cholesky)
l_cholesky_weibull[[i]]     <- as.matrix((l_results_all[[i]]$weibull$cholesky))
l_cholesky_lognormal[[i]]   <- (l_results_all[[i]]$lognormal$cholesky)
l_cholesky_loglogistic[[i]] <- (l_results_all[[i]]$loglogistic$cholesky)
}
# Load necessary library
library(openxlsx)
# Initialize workbook
wb_2 <- createWorkbook("AHEM student")
# Add worksheets with colors
addWorksheet(wb_2, "exponential", gridLines = FALSE, tabColour = "skyblue4")
addWorksheet(wb_2, "weibull",     gridLines = FALSE, tabColour = "coral3")
addWorksheet(wb_2, "lognormal",   gridLines = FALSE, tabColour = "skyblue")
addWorksheet(wb_2, "loglogistic", gridLines = FALSE, tabColour = "coral")
# Write m_cholesky_exponential directly
writeData(wb_2, sheet = "exponential", x = m_cholesky_exponential, rowNames = TRUE)
# Define the fixed order
fixed_order <- c("PFS caba", "PFS mito", "OS caba", "OS mito")
# Write l_cholesky_weibull in the fixed order
startRow <- 1
for (name in fixed_order) {
if (name %in% names(l_cholesky_weibull)) {
writeData(wb_2, sheet = "weibull", x = paste("Model:", name), startRow = startRow, startCol = 1)
writeData(wb_2, sheet = "weibull", x = l_cholesky_weibull[[name]], startRow = startRow + 1, rowNames = TRUE)
startRow <- startRow + nrow(l_cholesky_weibull[[name]]) + 3
}
}
# Write l_cholesky_lognormal in the fixed order
startRow <- 1
for (name in fixed_order) {
if (name %in% names(l_cholesky_lognormal)) {
writeData(wb_2, sheet = "lognormal", x = paste("Model:", name), startRow = startRow, startCol = 1)
writeData(wb_2, sheet = "lognormal", x = l_cholesky_lognormal[[name]], startRow = startRow + 1, rowNames = TRUE)
startRow <- startRow + nrow(l_cholesky_lognormal[[name]]) + 3
}
}
# Write l_cholesky_loglogistic in the fixed order
startRow <- 1
for (name in fixed_order) {
if (name %in% names(l_cholesky_loglogistic)) {
writeData(wb_2, sheet = "loglogistic", x = paste("Model:", name), startRow = startRow, startCol = 1)
writeData(wb_2, sheet = "loglogistic", x = l_cholesky_loglogistic[[name]], startRow = startRow + 1, rowNames = TRUE)
startRow <- startRow + nrow(l_cholesky_loglogistic[[name]]) + 3
}
}
# Save the workbook
saveWorkbook(wb_2, "output/output_cholensky.xlsx", overwrite = TRUE)
## 10.1 Model input for SA
library("darthtools")
library("dampack")
l_params_all <- list(
# Transition probabilities
# probability of dying
r_HS_SoC   = 0.05,  # rate of becoming sick when healthy, under standard of care
r_HS_trtA  = 0.04,  # rate of becoming sick when healthy, under treatment A
r_HS_trtB  = 0.02,  # rate of becoming sick when healthy, under treatment B
r_SD       = 0.1,   # rate of dying when sick
r_base     = 0.003, # rate of dying when healthy at t = 0
rr_annual  = 1.1,  # annual increase of mortality rate
# Costs
c_H       = 400,   # cost of one cycle in healthy state
c_S       = 1000,  # cost of one cycle in sick state
c_D       = 0,     # cost of one cycle in dead state
c_trtA    = 800,   # cost of treatment A (per cycle) in healthy state
c_trtB    = 1500,  # cost of treatment B (per cycle) in healthy state
# Utilities
u_H       = 1,     # utility when healthy
u_S       = 0.5,   # utility when sick
u_D       = 0,     # utility when dead
# Discount rates
d_e       = 0.03,  # discount rate per cycle equal discount of costs and QALYs by 3%
d_c       = 0.03,  # discount rate per cycle equal discount of costs and QALYs by 3%
# Time horizon
n_cycles  = 60,     # simulation time horizon (number of cycles)
cycle_length = 1
)
#------------------------------------------------------------------------------#
####              Calculate cost-effectiveness outcomes                     ####
#------------------------------------------------------------------------------#
#' Calculate cost-effectiveness outcomes
#'
#' \code{calculate_ce_out} calculates costs and effects for a given vector of parameters using a simulation model.
#' @param l_params_all List with all parameters of decision model
#' @param n_wtp Willingness-to-pay threshold to compute net monetary benefits (
#' NMB)
#' @return A dataframe with discounted costs, effectiveness and NMB.
#' @export
calculate_ce_out <- function(l_params_all, n_wtp = 10000 , verbose = verbose){ # User defined
with(as.list(l_params_all), {
########################### Process model inputs ###########################
## Model states
v_names_cycles  <- paste("cycle", 0:n_cycles)         # cycle names
v_names_states  <- c("H", "S", "D")       # state names
n_states        <- length(v_names_states)             # number of health states
### Strategies
v_names_str     <- c("Standard of Care",         # store the strategy names
"Treatment A",
"Treatment B")
n_str           <- length(v_names_str)           # number of strategies
## Within-cycle correction (WCC) using Simpson's 1/3 rule, alternative method = "half-cycle"
v_wcc <- gen_wcc(n_cycles = n_cycles,  method = "Simpson1/3")
### Cycle-specific discount weight for costs and effects
v_dwc   <- 1 / ((1 + (d_e * cycle_length)) ^ (0:n_cycles))
v_dwe   <- 1 / ((1 + (d_c * cycle_length)) ^ (0:n_cycles))
# rate of dying when healthy (time-dependent) - this is now a sequence of numbers
v_r_HD    <- r_base * rr_annual^(cycle_length * (0:(n_cycles - 1)))
###  Transition Probabilities
### Converting rates to probabilities
# function in darthtoolds, rate_to_prob based on p = 1 - exp( -r * cycle_length)
p_HS_SoC  <- rate_to_prob(r = r_HS_SoC,  t = cycle_length) # probability  of becoming sick when healthy, under SoC
p_HS_trtA <- rate_to_prob(r = r_HS_trtA, t = cycle_length) # probability of becoming sick when healthy, under treatment A
p_HS_trtB <- rate_to_prob(r = r_HS_trtB, t = cycle_length) # probability of becoming sick when healthy, under treatment B
p_SD      <- rate_to_prob(r = r_SD,      t = cycle_length) # probability of dying when sick
v_p_HD    <- rate_to_prob(r = v_r_HD,    t = cycle_length) # probability of dying when healthy (vector)
# All starting healthy
v_m_init <- c("H" = 1, "S" = 0, "D" = 0)
###################### Construct state-transition models ###################
### Initialize cohort trace for SoC. Set all values to zero
# dimensions are number of cycles + 1 (for initial state) and number of states
m_M_SoC <- matrix(0,
nrow = (n_cycles + 1), ncol = n_states,
dimnames = list(v_names_cycles, v_names_states))
# Store the initial state vector in the first row of the cohort trace
m_M_SoC[1, ] <- v_m_init
## Initialize cohort traces for treatments A and B
# Structure and initial states are the same as for SoC
m_M_trtA <- m_M_trtB <- m_M_SoC
## Create transition probability arrays for strategy SoC
### Initialize transition probability array for strategy SoC
# All transitions to a non-death state are assumed to be conditional on survival
a_P_SoC <- array(0,  # Create 3-D array
dim = c(n_states, n_states, n_cycles),
dimnames = list(v_names_states, v_names_states,
v_names_cycles[-length(v_names_cycles)])) # name the dimensions of the array
### Fill in array
## Standard of Care
# from Healthy
a_P_SoC["H", "H", ] <- (1 - v_p_HD) * (1 - p_HS_SoC)
a_P_SoC["H", "S", ] <- (1 - v_p_HD) *      p_HS_SoC
a_P_SoC["H", "D", ] <-      v_p_HD
# from Sick
a_P_SoC["S", "S", ] <- 1 - p_SD
a_P_SoC["S", "D", ] <-     p_SD
# from Dead
a_P_SoC["D", "D", ] <- 1
## Treatment A
a_P_trtA <- a_P_SoC # Store array, only replace values that are different in the treatment
a_P_trtA["H", "H", ] <- (1 - v_p_HD) * (1 - p_HS_trtA)
a_P_trtA["H", "S", ] <- (1 - v_p_HD) *      p_HS_trtA
## Treatment B
a_P_trtB <- a_P_SoC
a_P_trtB["H", "H", ] <- (1 - v_p_HD) * (1 - p_HS_trtB)
a_P_trtB["H", "S", ] <- (1 - v_p_HD) *      p_HS_trtB
## Check if transition array and probabilities are valid
# Check that transition probabilities are in [0, 1]
check_transition_probability(a_P_SoC,  verbose = TRUE)
check_transition_probability(a_P_trtA, verbose = TRUE)
check_transition_probability(a_P_trtB, verbose = TRUE)
# Check that all rows sum to 1
check_sum_of_transition_array(a_P_SoC,  n_states = n_states, n_cycles = n_cycles, verbose = TRUE)
check_sum_of_transition_array(a_P_trtA, n_states = n_states, n_cycles = n_cycles, verbose = TRUE)
check_sum_of_transition_array(a_P_trtB, n_states = n_states, n_cycles = n_cycles, verbose = TRUE)
for(t in 1:n_cycles){
## Fill in cohort trace
# For SoC
m_M_SoC[t + 1, ]  <- m_M_SoC[t, ]  %*% a_P_SoC[, , t]
# For strategy A
m_M_trtA[t + 1, ] <- m_M_trtA[t, ] %*% a_P_trtA[, , t]
# For strategy B
m_M_trtB[t + 1, ] <- m_M_trtB[t, ] %*% a_P_trtB[, , t]
}
## Store the cohort traces in a list
l_m_M <- list(SoC =  m_M_SoC,
A   =  m_M_trtA,
B   =  m_M_trtB)
names(l_m_M) <- v_names_str
## Scale by the cycle length
# Standard of Care
# vector of state QALYs accrued each cycle
v_u_SoC    <- c(H  = u_H,
S  = u_S,
D  = u_D) * cycle_length
# vector of state costs accrued each cycle
v_c_SoC    <- c(H  = c_H,
S  = c_S,
D  = c_D) * cycle_length
# Treatment A
# vector of state QALYs accrued each cycle
v_u_trtA   <- c(H  = u_H,
S  = u_S,
D  = u_D) * cycle_length
# vector of state costs accrued each cycle
v_c_trtA   <- c(H  = c_H + c_trtA,
S  = c_S,
D  = c_D) * cycle_length
# Treatment B
# vector of state QALYs accrued each cycle
v_u_trtB   <- c(H  = u_H,
S  = u_S,
D  = u_D) * cycle_length
# vector of state costs accrued each cycle
v_c_trtB   <- c(H  = c_H + c_trtB,
S  = c_S,
D  = c_D) * cycle_length
## Store state rewards
# Store the vectors of state utilities for each strategy in a list
l_u   <- list(SoQ = v_u_SoC,
A   = v_u_trtA,
B   = v_u_trtB)
# Store the vectors of state cost for each strategy in a list
l_c   <- list(SoQ = v_c_SoC,
A   = v_c_trtA,
B   = v_c_trtB)
# assign strategy names to matching items in the lists
names(l_u) <- names(l_c) <- v_names_str
# Create empty vectors to store total utilities and costs
v_tot_qaly <- v_tot_cost <- vector(mode = "numeric", length = n_str)
names(v_tot_qaly) <- names(v_tot_cost) <- v_names_str
## Loop through each strategy and calculate total utilities and costs
for (i in 1:n_str) {
v_u_str <- l_u[[i]]   # select the vector of state utilities for the i-th strategy
v_c_str <- l_c[[i]]   # select the vector of state costs for the i-th strategy
### Expected QALYs and costs per cycle
## Vector of QALYs and Costs
# Apply state rewards
v_qaly_str <- l_m_M[[i]] %*% v_u_str # sum the utilities of all states for each cycle
v_cost_str <- l_m_M[[i]] %*% v_c_str # sum the costs of all states for each cycle
### Discounted total expected QALYs and Costs per strategy and apply within-cycle correction if applicable
# QALYs
v_tot_qaly[i] <- t(v_qaly_str) %*% (v_dwe * v_wcc)
# Costs
v_tot_cost[i] <- t(v_cost_str) %*% (v_dwc * v_wcc)
}
## data.frame with discounted costs, effectiveness and NMB
df_ce <- data.frame(Strategy = v_names_str,
Cost     = v_tot_cost,
Effect   = v_tot_qaly)
return(df_ce)
}
)
}
df_ce_out <- calculate_ce_out(l_params_all)
## Incremental cost-effectiveness ratios (ICERs)
df_cea <- calculate_icers(cost       = df_ce_out$Cost,
effect     = df_ce_out$Effect,
strategies = df_ce_out$Strategy)
df_cea
