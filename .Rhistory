v_names_dist
get_survival_parameters(data = df_OS_caba, distributions = c("exponential, "lognormal"))
# The function get_survival_parameters get the values for each of the selected distributions
get_survival_parameters <- function(data, distributions = c("exponential", "weibull", "lognormal", "loglogistic")){
# Arguments
# data: data from KM-curve using the Henley and Hoyle method
# distributions: the distributions to explore, default is exponential and weibull
# Returns
#
l_results <- l_model <- l_cholesky <- list() # create a list to store the model results
v_AIC <- v_intercept <- v_log_scale <- vector()
# Create a matrix with all information
m_model_parameters <- matrix(NA, nrow = 3, ncol = length(distributions),
dimnames = list(c("AIC", "intercept", "log(scale)"),
distributions))
# Extract the timepoints from the dataset
times_start <- c(rep(data$start_time_censor, data$n_censors), rep(data$start_time_event, data$n_events))
times_end   <- c(rep(data$end_time_censor, data$n_censors),   rep(data$end_time_event,   data$n_events))
#  adding times for patients at risk at last time point
times_start <- c(times_start, rep(30, 4))
times_end   <- c(times_end, rep(10000, 4))
for(d in distributions){ # for each of the distributions
# estimate a model
model <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = d)
n_AIC <- -2 * summary(model)$loglik[1] + 2 * ifelse(d == "exponential", 1 , 2)
n_intercept <- summary(model)$table[1]
ifelse(d != "exponential",
n_log_scale<- summary(model)$table[2],
n_log_scale <- NA )  # intercept parameter if not exponential
# log scale parameter
m_cholesky  <- t(chol(summary(model)$var)) # Get the cholesky matrix
# Create a list for each of the distributions
l_results[[d]] <- list(model = model,
AIC = n_AIC,
intercept = n_intercept,
log_scale = n_log_scale,
cholesky = m_cholesky
)
v_AIC[[d]] <- n_AIC # store the AIC value in a vector, usefull to compare
v_intercept[[d]]  <- n_intercept
v_log_scale[[d]]  <- n_log_scale
# Add the vector for the AIC values for comparison
l_results$AIC  <- v_AIC # save the vector of all the AIC values as a separate item in the li
m_model_parameters["AIC",  ]       <- v_AIC
m_model_parameters["intercept",  ] <- v_intercept
m_model_parameters["log(scale)", ] <- v_log_scale
m_model_parameters <- round(m_model_parameters, 3) # Print matrix with rounded values
l_results$summary <- m_model_parameters # save the vector of all the AIC values as a separate item in the list                    # useful for comparison reasons
}
return(l_results) # return the list with all the dataset specific model parameters
} # close function
# Loop over the different data sets
l_results_all <- list() # create a list to store the results
for(df in names(l_data_survival)){ # for each of the names in the list - run the function
l_results_all[[df]] <- get_survival_parameters(data = l_data_survival[[df]])
}
# The function get_survival_parameters get the values for each of the selected distributions
get_survival_parameters <- function(data, distributions = c("exponential", "weibull", "lognormal", "loglogistic")){
# Arguments
# data: data from KM-curve using the Henley and Hoyle method
# distributions: the distributions to explore, default is exponential and weibull
# Returns
#
l_results <- l_model <- l_cholesky <- list() # create a list to store the model results
v_AIC <- v_intercept <- v_log_scale <- vector()
# Create a matrix with all information
m_model_parameters <- matrix(NA, nrow = 3, ncol = length(distributions),
dimnames = list(c("AIC", "intercept", "log(scale)"),
distributions))
# Extract the timepoints from the dataset
times_start <- c(rep(data$start_time_censor, data$n_censors), rep(data$start_time_event, data$n_events))
times_end   <- c(rep(data$end_time_censor, data$n_censors),   rep(data$end_time_event,   data$n_events))
#  adding times for patients at risk at last time point
times_start <- c(times_start, rep(30, 4))
times_end   <- c(times_end, rep(10000, 4))
for(d in distributions){ # for each of the distributions
# estimate a model
model <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = d)
n_AIC <- -2 * summary(model)$loglik[1] + 2 * ifelse(d == "exponential", 1 , 2)
n_intercept <- summary(model)$table[1]
ifelse(d != "exponential",
n_log_scale<- summary(model)$table[2],
n_log_scale <- NA )  # intercept parameter if not exponential
# log scale parameter
m_cholesky  <- t(chol(summary(model)$var)) # Get the cholesky matrix
# Create a list for each of the distributions
l_results[[d]] <- list(model = model,
AIC = n_AIC,
intercept = n_intercept,
log_scale = n_log_scale,
cholesky = m_cholesky
)
v_AIC[[d]] <- n_AIC # store the AIC value in a vector, usefull to compare
v_intercept[[d]]  <- n_intercept
v_log_scale[[d]]  <- n_log_scale
# Add the vector for the AIC values for comparison
l_results$AIC  <- v_AIC # save the vector of all the AIC values as a separate item in the li
m_model_parameters["AIC",  ]       <- v_AIC
m_model_parameters["intercept",  ] <- v_intercept
m_model_parameters["log(scale)", ] <- v_log_scale
m_model_parameters <- round(m_model_parameters, 3) # Print matrix with rounded values
l_results$summary <- m_model_parameters # save the vector of all the AIC values as a separate item in the list                    # useful for comparison reasons
}
return(l_results) # return the list with all the dataset specific model parameters
} # close function
# Loop over the different data sets
l_results_all <- list() # create a list to store the results
for(df in names(l_data_survival)){ # for each of the names in the list - run the function
l_results_all[[df]] <- get_survival_parameters(data = l_data_survival[[df]])
}
# Create a matrix with all information
m_model_parameters <- matrix(NA, nrow = 3, ncol = length(distributions),
dimnames = list(c("AIC", "intercept", "log(scale)"),
distributions))
m_model_parameters
m_model_parameters
distributions = c("exponential", "weibull", "lognormal", "loglogistic")
distributions
l_results <- l_model <- l_cholesky <- list() # create a list to store the model results
v_AIC <- v_intercept <- v_log_scale <- vector()
# Create a matrix with all information
m_model_parameters <- matrix(NA, nrow = 3, ncol = length(distributions),
dimnames = list(c("AIC", "intercept", "log(scale)"),
distributions))
m_model_parameters
# The function get_survival_parameters get the values for each of the selected distributions
get_survival_parameters <- function(data, distributions = c("exponential", "weibull", "lognormal", "loglogistic")){
# Arguments
# data: data from KM-curve using the Henley and Hoyle method
# distributions: the distributions to explore, default is exponential and weibull
# Returns
#
l_results <- l_model <- l_cholesky <- list() # create a list to store the model results
v_AIC <- v_intercept <- v_log_scale <- vector()
# Create a matrix with all information
m_model_parameters <- matrix(NA, nrow = 3, ncol = length(distributions),
dimnames = list(c("AIC", "intercept", "log(scale)"),
distributions))
# Extract the timepoints from the dataset
times_start <- c(rep(data$start_time_censor, data$n_censors), rep(data$start_time_event, data$n_events))
times_end   <- c(rep(data$end_time_censor, data$n_censors),   rep(data$end_time_event,   data$n_events))
#  adding times for patients at risk at last time point
times_start <- c(times_start, rep(30, 4))
times_end   <- c(times_end, rep(10000, 4))
for(d in distributions){ # for each of the distributions
# estimate a model
model <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = d)
n_AIC <- -2 * summary(model)$loglik[1] + 2 * ifelse(d == "exponential", 1 , 2)
n_intercept <- summary(model)$table[1]
ifelse(d != "exponential",
n_log_scale<- summary(model)$table[2],
n_log_scale <- NA )  # intercept parameter if not exponential
# log scale parameter
m_cholesky  <- t(chol(summary(model)$var)) # Get the cholesky matrix
# Create a list for each of the distributions
l_results[[d]] <- list(model = model,
AIC = n_AIC,
intercept = n_intercept,
log_scale = n_log_scale,
cholesky = m_cholesky
)
#v_AIC[[d]] <- n_AIC # store the AIC value in a vector, usefull to compare
#v_intercept[[d]]  <- n_intercept
#v_log_scale[[d]]  <- n_log_scale
# Add the vector for the AIC values for comparison
#l_results$AIC  <- v_AIC # save the vector of all the AIC values as a separate item in the li
m_model_parameters["AIC", d ]       <- v_AIC
m_model_parameters["intercept", d ] <- v_intercept
m_model_parameters["log(scale)",d ] <- v_log_scale
m_model_parameters <- round(m_model_parameters, 3) # Print matrix with rounded values
l_results$summary <- m_model_parameters # save the vector of all the AIC values as a separate item in the list                    # useful for comparison reasons
}
return(l_results) # return the list with all the dataset specific model parameters
} # close function
# Loop over the different data sets
l_results_all <- list() # create a list to store the results
for(df in names(l_data_survival)){ # for each of the names in the list - run the function
l_results_all[[df]] <- get_survival_parameters(data = l_data_survival[[df]])
}
# Create a matrix with all information
m_model_parameters <- matrix(NA, nrow = 3, ncol = length(distributions),
dimnames = list(c("AIC", "intercept", "log(scale)"),
distributions))
m_model_parameters
which[[distributions == d]]
d
d <- distributions[[1]]
d
l_results <- l_model <- l_cholesky <- list() # create a list to store the model results
v_AIC <- v_intercept <- v_log_scale <- vector()
v_AIC
# Create a matrix with all information
m_model_parameters <- matrix(NA, nrow = 3, ncol = length(distributions),
dimnames = list(c("AIC", "intercept", "log(scale)"),
distributions))
m_model_parameters
distributions
# Extract the timepoints from the dataset
times_start <- c(rep(data$start_time_censor, data$n_censors), rep(data$start_time_event, data$n_events))
times_end   <- c(rep(data$end_time_censor, data$n_censors),   rep(data$end_time_event,   data$n_events))
#  adding times for patients at risk at last time point
times_start <- c(times_start, rep(30, 4))
times_end   <- c(times_end, rep(10000, 4))
d <- distributions[1]
d
# estimate a model
model <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = d)
n_AIC <- -2 * summary(model)$loglik[1] + 2 * ifelse(d == "exponential", 1 , 2)
n_AIC
n_intercept <- summary(model)$table[1]
n_intercept
ifelse(d != "exponential",
n_log_scale<- summary(model)$table[2],
n_log_scale <- NA )  # intercept parameter if not exponential
n_intercept
n_log_scale
m_cholesky  <- t(chol(summary(model)$var)) # Get the cholesky matrix
m_cholesky
# Create a list for each of the distributions
l_results[[d]] <- list(model = model,
AIC = n_AIC,
intercept = n_intercept,
log_scale = n_log_scale,
cholesky = m_cholesky
)
l_results
m_model_parameters
distributions[,d]
d
which(d == distributions)
m_model_parameters["AIC",  which(d == distributions)]       <- v_AIC
v_AIC
m_model_parameters["AIC",  which(d == distributions)]       <- n_AIC
m_model_parameters
m_model_parameters["AIC",  which(d == distributions)]       <- n_AIC
m_model_parameters["intercept",  which(d == distributions)] <- n_intercept
m_model_parameters["log(scale)", which(d == distributions)] <- n_log_scale
m_model_parameters <- round(m_model_parameters, 3) # Print matrix with rounded values
m_model_parameters
l_results$summary <- m_model_parameters # save the vector of all the AIC values as a separate item in the list                    # useful for comparison reasons
# The function get_survival_parameters get the values for each of the selected distributions
get_survival_parameters <- function(data, distributions = c("exponential", "weibull", "lognormal", "loglogistic")){
# Arguments
# data: data from KM-curve using the Henley and Hoyle method
# distributions: the distributions to explore, default is exponential and weibull
# Returns
#
l_results <- l_model <- l_cholesky <- list() # create a list to store the model results
v_AIC <- v_intercept <- v_log_scale <- vector()
# Create a matrix with all information
m_model_parameters <- matrix(NA, nrow = 3, ncol = length(distributions),
dimnames = list(c("AIC", "intercept", "log(scale)"),
distributions))
# Extract the timepoints from the dataset
times_start <- c(rep(data$start_time_censor, data$n_censors), rep(data$start_time_event, data$n_events))
times_end   <- c(rep(data$end_time_censor, data$n_censors),   rep(data$end_time_event,   data$n_events))
#  adding times for patients at risk at last time point
times_start <- c(times_start, rep(30, 4))
times_end   <- c(times_end, rep(10000, 4))
for(d in distributions){ # for each of the distributions
# estimate a model
model <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = d)
n_AIC <- -2 * summary(model)$loglik[1] + 2 * ifelse(d == "exponential", 1 , 2)
n_intercept <- summary(model)$table[1]
ifelse(d != "exponential",
n_log_scale<- summary(model)$table[2],
n_log_scale <- NA )  # intercept parameter if not exponential
# log scale parameter
m_cholesky  <- t(chol(summary(model)$var)) # Get the cholesky matrix
# Create a list for each of the distributions
l_results[[d]] <- list(model = model,
AIC = n_AIC,
intercept = n_intercept,
log_scale = n_log_scale,
cholesky = m_cholesky
)
#v_AIC[[d]] <- n_AIC # store the AIC value in a vector, usefull to compare
#v_intercept[[d]]  <- n_intercept
#v_log_scale[[d]]  <- n_log_scale
# Add the vector for the AIC values for comparison
#l_results$AIC  <- v_AIC # save the vector of all the AIC values as a separate item in the li
m_model_parameters["AIC",        which(d == distributions)] <- n_AIC
m_model_parameters["intercept",  which(d == distributions)] <- n_intercept
m_model_parameters["log(scale)", which(d == distributions)] <- n_log_scale
m_model_parameters <- round(m_model_parameters, 3) # Print matrix with rounded values
l_results$summary <- m_model_parameters # save the vector of all the AIC values as a separate item in the list                    # useful for comparison reasons
}
return(l_results) # return the list with all the dataset specific model parameters
} # close function
# Loop over the different data sets
l_results_all <- list() # create a list to store the results
for(df in names(l_data_survival)){ # for each of the names in the list - run the function
l_results_all[[df]] <- get_survival_parameters(data = l_data_survival[[df]])
}
l_results_all$`OS mito`$summary
#With this line of code you get all the AIC values
for(i in v_names_data){
print(l_results_all[[i]]$summary)
}
#With this line of code you get all the AIC values
for(i in v_names_data){
print(v_names_data[i])
print(l_results_all[[i]]$summary)
}
#With this line of code you get all the AIC values
for(i in v_names_data){
print(i)
print(l_results_all[[i]]$summary)
}
for(i in v_names_data){
print(i)
print(l_results_all[[i]]$summary)
}
l_results_all$`OS mito`$lognormal$cholesky
# Part 0.0
# Set up R
# The R code to fit survival curves to the estimated pseudo individual patient level data
rm(list = ls(all = TRUE)) # clear all the information in the environment
#install.packages(c("survival", "readxl")) #Uncommand if you have to install
library(survival)         # load the survival package
library(readxl)
# Load the data from Excel
# Make sure you have first filled the Excel with the information
# The code na.omit removes the rows from the data that are empty
df_OS_mito  <- na.omit(read_excel("Hoyle_and_Henley_Bahl_OS_Mito.xlsm", sheet = "R data"))
df_OS_caba  <- na.omit(read_excel("Hoyle_and_Henley_Bahl_OS_Caba.xlsm", sheet = "R data"))
df_PFS_mito <- na.omit(read_excel("Hoyle_and_Henley_PFS_Mito.xlsm",     sheet = "R data"))
df_PFS_caba <- na.omit(read_excel("Hoyle_and_Henley_PFS_Caba.xlsm",     sheet = "R data"))
# Create a list with the dataframes
l_data_survival <- list("OS mito"  = df_OS_mito,
"OS caba"  = df_OS_caba,
"PFS mito" = df_PFS_mito,
"PFS caba" = df_PFS_caba)
l_data_survival
v_names_trt  <- c("Mitoxantrone", "Cabazitaxel") # vector with the treatment names
v_names_data <- c("OS mito", "OS caba", "PFS mito", "PFS caba") # vector for the different data sets
v_names_dist <- c("exponential", "weibull", "lognormal", "loglogistic") # define the distribution we are evaluating
l_data_survival$`OS mito`
View(df_OS_caba)
View(df_OS_mito)
# Load the data from Excel
# Make sure you have first filled the Excel with the information
# The code na.omit removes the rows from the data that are empty
df_OS_mito  <- na.omit(read_excel("Hoyle_and_Henley_Bahl_OS_Mito.xlsm", sheet = "R data"))
df_OS_mito
# Part 0.0
# Set up R
# The R code to fit survival curves to the estimated pseudo individual patient level data
rm(list = ls(all = TRUE)) # clear all the information in the environment
#install.packages(c("survival", "readxl")) #Uncommand if you have to install
library(survival)         # load the survival package
library(readxl)
# Load the data from Excel
# Make sure you have first filled the Excel with the information
# The code na.omit removes the rows from the data that are empty
df_OS_mito  <- na.omit(read_excel("Hoyle_and_Henley_Bahl_OS_Mito.xlsm", sheet = "R data"))
View(df_OS_mito)
# Alternative; save data Excel data a .txt files and load the data
df_OS_mito  <- read.table("OSmito.txt",  header = TRUE)
# Load the data from Excel
# Make sure you have first filled the Excel with the information
# The code na.omit removes the rows from the data that are empty
df_OS_mito  <- na.omit(read_excel("Hoyle_and_Henley_Bahl_OS_Mito.xlsm", sheet = "R data"))
v_prob <- (0.3, rep (0.5, 10))
v_prob <- (c(0.3, rep (0.5, 10))
v_prob <- (c(0.3, rep (0.5, 10)))
v_prob
v_prob <- c(0.3, rep (0.5, 10))
v_prob
m_T <- c("H", rep("S", 5), rep ("D", 5))
m_T
c(1, 0, 1, 0,3 ,4 ,5 )
v_test <- c(1, 0, 1, 0,3 ,4 ,5, 1, 3, 5, 0)
v_prob(m_T == "S")
v_prob <- c(0.3, rep (0.5, 10))
v_prob
m_T <- c("H", rep("S", 5), rep ("D", 5))
m_T
v_test <- c(1, 0, 1, 0,3 ,4 ,5, 1, 3, 5, 0)
v_prob(m_T == "S")
v_prob[m_T == "S"]
v_prob[v_test]
v_prob[v_test & m_T == "S" & ]
v_prob[v_test & m_T == "S" ]
v_prob <- c(0.3, rep (0.5, 10))
v_prob
m_T <- c("H", rep("S", 5), rep ("D", 5))
m_T
v_test <- c(1, 0, 1, 0, 3 ,4 ,5, 1, 3, 5, 0)
v_prob[v_test]
m_T
v_prob[v_test & m_T == "S" ]
v_test[m_T == "S"] <- v_test[m_T == "S"] + 1
v_test
v_test[m_T == "T"] <- v_test[m_T == "T"] + 1
v_test
# Advanced Health Economic Modeling
# Erasmus University Rotterdam
# Course coordinator: Maiwenn Al, PhD
#### IMPORTANT ####
# READ ALL THE GREEN TEXT
# MAKE SURE YOU OPENED THE AHEM COMPUTER LAB PROJECTS
###################
# How to open an Rproject? #
# You do so by clicking on the file .Rproj
# In the right upper corner of R studio you should see AHEM
# This document is structured in two parts:
## In part I ##
## What: we demonstrate the R code functions step by step using one of the data sets
## Aim:  Helps you understand what the code is doing and makes is relatively easy to see all the intermediate steps
## In part II ##
## What: we created loops and functions of the steps presented in part I.
## Aim:  Run the code from part I for all the data sets.
# Abbreviations
# OS:   overall survival
# PFS:  progression free survival
# mito: Mitoxantrone
# caba: Cabazitaxel
# Part 0.0
# Set up R
# The R code to fit survival curves to the estimated pseudo individual patient level data
rm(list = ls(all = TRUE)) # clear all the information in the environment
#install.packages(c("survival", "readxl")) #Uncommand if you have to install
library(survival)         # load the survival package
library(readxl)
# Load the data from Excel
# Make sure you have first filled the Excel with the information
# The code na.omit removes the rows from the data that are empty
df_OS_mito  <- na.omit(read_excel("Hoyle_and_Henley_Bahl_OS_Mito.xlsm", sheet = "R data"))
df_OS_caba  <- na.omit(read_excel("Hoyle_and_Henley_Bahl_OS_Caba.xlsm", sheet = "R data"))
df_PFS_mito <- na.omit(read_excel("Hoyle_and_Henley_PFS_Mito.xlsm",     sheet = "R data"))
df_PFS_caba <- na.omit(read_excel("Hoyle_and_Henley_PFS_Caba.xlsm",     sheet = "R data"))
# Alternative; save data Excel data a .txt files and load the data
#df_OS_mito  <- read.table("OSmito.txt",  header = TRUE)
#df_OS_caba  <- read.table("OScaba.txt",  header = TRUE)
#df_PFS_mito <- read.table("PFSmito.txt", header = TRUE)
#df_PFS_caba <- read.table("PFScaba.txt", header = TRUE)
# *STAR*: Extra learning about R when you like R to read the files.
#l_data_survival <- list()
#files <- list.files(pattern = "Hoyle_and_Henley.+xlsm") # Let R find files with the following pattern
#for (i in files){ # For each of these files
#  x <- read_excel(i, sheet = "R data") # open the R data sheet
#  assign(paste("df_", gsub("Hoyle_and_Henley_|.xlsm|Hoyle_and_Henley_Bahl_", "", i), sep = ""), x) # give this data a name
#  l_data_survival[[paste(gsub("Hoyle_and_Henley_|.xlsm|Hoyle_and_Henley_Bahl_", "", i))]] <- x
#  remove(x)
#}
# Create a list with the dataframes
l_data_survival <- list("OS mito"  = df_OS_mito,
"OS caba"  = df_OS_caba,
"PFS mito" = df_PFS_mito,
"PFS caba" = df_PFS_caba)
v_names_trt  <- c("Mitoxantrone", "Cabazitaxel") # vector with the treatment names
v_names_data <- c("OS mito", "OS caba", "PFS mito", "PFS caba") # vector for the different data sets
v_names_dist <- c("exponential", "weibull", "lognormal", "loglogistic") # define the distribution we are evaluating
#df_OS_mito %>%
#  mutate(times_start = c(rep(start_time_censor, n_censors), rep(start_time_event, n_events)))
## 1.0 Part I
# We store the data from df_OS_mito to the general data name data
# We attach data to the R search path, this means that this database is searched by R
# when evaluating a variable in the functions below
data <- df_OS_mito
attach(data)
# Extract the timepoints from the dataset
times_start <- c(rep(start_time_censor, n_censors), rep(start_time_event, n_events))
times_end   <- c(rep(end_time_censor, n_censors),   rep(end_time_event,   n_events))
#  adding times for patients at risk at last time point
times_start <- c(times_start, rep(30, 4))
times_end   <- c(times_end, rep(10000, 4))
df_times    <- cbind(times_start, times_end)
head(df_times)
## 1.1 Create models for each of the distributions
model_exp  <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = "exponential")   # Exponential function, interval censoring
model_wei  <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = "weibull")       # Weibull function, interval censoring
model_logn <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = "lognormal")     # Lognormal function, interval censoring
model_logl <- survreg(Surv(times_start, times_end, type = "interval2") ~ 1, dist = "loglogistic")   # Loglogistic function, interval censoring
# Calculate the AIC values
# Equation: - 2 * log L + k * edf
# L: likelihood
# edf: equivalent degrees of freedom
# k = 2 correspond to the transitional AIC, using k = lo
AIC_exp  <- -2 * summary(model_exp)$loglik[1]  + 2 * 1  #  AIC for exponential distribution
AIC_wei  <- -2 * summary(model_wei)$loglik[1]  + 2 * 2  #  AIC for Weibull, which is a 2-parameter distribution
AIC_logn <- -2 * summary(model_logn)$loglik[1] + 2 * 2  #  AIC for lognormal, which is a 2-parameter distribution
AIC_logl <- -2 * summary(model_logl)$loglik[1] + 2 * 2  #  AIC for log-logistic, which is a 2-parameter distribution
#  Compare AIC values
v_AIC <- c(exponential = AIC_exp, weibull = AIC_wei,
lognormal = AIC_logn, loglogistic = AIC_logl) # create a vector of the values
v_AIC[order(-v_AIC)]  # Print in order
#  Intercept and logscale parameters
intercept_exp  <- summary(model_exp)$table ["(Intercept)", "Value"]  # intercept parameter for exponential
intercept_wei  <- summary(model_wei)$table ["(Intercept)", "Value"]  # intercept parameter for weibull
intercept_logn <- summary(model_logn)$table["(Intercept)", "Value"]  # intercept parameter for lognormal
intercept_logl <- summary(model_logl)$table["(Intercept)", "Value"]  # intercept parameter for loglogistic
log_scale_wei  <- summary(model_wei)$table ["Log(scale)", "Value"]   # log scale parameter for weibull
log_scale_logn <- summary(model_logn)$table["Log(scale)", "Value"]   # log scale parameter for lognormal
log_scale_logl <- summary(model_logl)$table["Log(scale)", "Value"]   # log scale parameter for loglogistic
# Create vectors for the intercept and log scale parameters
v_intercept       <- c(intercept_exp, intercept_wei, intercept_logn, intercept_logl)
v_log_scale       <- c(NA,           log_scale_wei, log_scale_logn, log_scale_logl)
names(v_intercept) <- names(v_intercept)  <- v_names_dist
# Create a matrix with all information
m_model_parameters_OS_mito <- matrix(NA, nrow = 3, ncol = length(v_names_dist),
dimnames = list(c("AIC", "intercept", "log(scale)"),
v_names_dist))
m_model_parameters_OS_mito["AIC",  ]       <- v_AIC
m_model_parameters_OS_mito["intercept",  ] <- v_intercept
m_model_parameters_OS_mito["log(scale)", ] <- v_log_scale
round(m_model_parameters_OS_mito, 3) # Print matrix with rounded values
#  For the Probabilistic Sensitivity Analysis, we need the Cholesky matrix,
# this matrix which captures the variance and covariance of parameters
cholesky_exp  <- t(chol(summary(model_exp)$var))    #  Cholesky matrix for exponential
cholesky_wei  <- t(chol(summary(model_wei)$var))    #  Cholesky matrix for weibull
